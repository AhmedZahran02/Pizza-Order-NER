{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d7df332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T18:05:26.822092Z",
     "iopub.status.busy": "2024-12-04T18:05:26.821814Z",
     "iopub.status.idle": "2024-12-04T18:05:31.425776Z",
     "shell.execute_reply": "2024-12-04T18:05:31.424865Z"
    },
    "papermill": {
     "duration": 4.610478,
     "end_time": "2024-12-04T18:05:31.427870",
     "exception": false,
     "start_time": "2024-12-04T18:05:26.817392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23005d72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T18:05:31.436213Z",
     "iopub.status.busy": "2024-12-04T18:05:31.435469Z",
     "iopub.status.idle": "2024-12-04T18:05:57.171899Z",
     "shell.execute_reply": "2024-12-04T18:05:57.170917Z"
    },
    "papermill": {
     "duration": 25.74229,
     "end_time": "2024-12-04T18:05:57.173643",
     "exception": false,
     "start_time": "2024-12-04T18:05:31.431353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data Started\n",
      "Loading Data Done\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "def load_data(file_x, file_y):\n",
    "    with open(file_x, 'r') as fx, open(file_y, 'r') as fy:\n",
    "        sentences = fx.read().strip().split('\\n')\n",
    "        labels = fy.read().strip().split('\\n')\n",
    "    return [sentence.split(\",\") for sentence in sentences], [label.split(',') for label in labels]\n",
    "\n",
    "print(\"Loading Data Started\")\n",
    "train_sentences, train_labels = load_data('database/labeler/x_train.txt', 'database/labeler/y_train.txt')\n",
    "test_sentences, test_labels = load_data('database/labeler/x_dev.txt', 'database/labeler/y_dev.txt')\n",
    "print(\"Loading Data Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91ddc0dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T18:05:57.181433Z",
     "iopub.status.busy": "2024-12-04T18:05:57.181158Z",
     "iopub.status.idle": "2024-12-04T18:05:58.738572Z",
     "shell.execute_reply": "2024-12-04T18:05:58.737647Z"
    },
    "papermill": {
     "duration": 1.563232,
     "end_time": "2024-12-04T18:05:58.740352",
     "exception": false,
     "start_time": "2024-12-04T18:05:57.177120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Vocab Started\n",
      "Building Vocab Done\n"
     ]
    }
   ],
   "source": [
    "# Build Vocabulary\n",
    "FREQ_THRESH = 0\n",
    "\n",
    "def build_vocab():\n",
    "    vocab = set()\n",
    "    with open(\"database/labeler/vocabulary.txt\", \"r\") as fv:\n",
    "        for line in fv: \n",
    "            voc, thresh = line.strip().split(\",\")\n",
    "            if int(thresh) > FREQ_THRESH:\n",
    "                vocab.add(voc)\n",
    "    word2idx = {word: idx + 2 for idx, word in enumerate(sorted(vocab))}  # Reserve 0 for padding, 1 for unknown words\n",
    "    word2idx['<PAD>'] = 0\n",
    "    word2idx['<UNK>'] = 1\n",
    "    return word2idx\n",
    "\n",
    "def build_label_vocab(labels):\n",
    "    vocab = {label for label_list in labels for label in label_list}\n",
    "    label2idx = {label: idx for idx, label in enumerate(sorted(vocab))}\n",
    "    return label2idx\n",
    "\n",
    "print(\"Building Vocab Started\")\n",
    "word2idx = build_vocab()\n",
    "label2idx = build_label_vocab(train_labels)\n",
    "idx2label = {idx: label for label, idx in label2idx.items()}\n",
    "print(\"Building Vocab Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0245fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T18:05:58.749295Z",
     "iopub.status.busy": "2024-12-04T18:05:58.749049Z",
     "iopub.status.idle": "2024-12-04T18:05:58.753459Z",
     "shell.execute_reply": "2024-12-04T18:05:58.752634Z"
    },
    "papermill": {
     "duration": 0.011279,
     "end_time": "2024-12-04T18:05:58.755174",
     "exception": false,
     "start_time": "2024-12-04T18:05:58.743895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200millilit,2\n",
      "500millilit,3\n",
      "500ml,4\n",
      "DIGIT,5\n",
      "ale,6\n",
      "alfredo,7\n",
      "all,8\n",
      "also,9\n",
      "american,10\n",
      "an,11\n",
      "anchovi,12\n",
      "ani,13\n",
      "appl,14\n",
      "applewood,15\n",
      "artichok,16\n",
      "arugula,17\n",
      "avoid,18\n",
      "bacon,19\n",
      "balsam,20\n",
      "balzam,21\n",
      "banana,22\n",
      "barbecu,23\n",
      "basil,24\n",
      "bay,25\n",
      "bbq,26\n",
      "bean,27\n",
      "beef,28\n",
      "big,29\n",
      "bit,30\n",
      "black,31\n",
      "bottl,32\n",
      "broccoli,33\n",
      "brocoli,34\n",
      "buffalo,35\n",
      "can,36\n",
      "caramel,37\n",
      "carrot,38\n",
      "cauliflow,39\n",
      "cheddar,40\n",
      "chees,41\n",
      "cheeseburg,42\n",
      "cherri,43\n",
      "chicago,44\n",
      "chicken,45\n",
      "chorizo,46\n",
      "chorrizo,47\n",
      "coffe,48\n",
      "coke,49\n",
      "combin,50\n",
      "crust,51\n",
      "cumin,52\n",
      "deep,53\n",
      "deepdish,54\n",
      "dew,55\n",
      "diet,56\n",
      "dish,57\n",
      "doctor,58\n",
      "dough,59\n",
      "dr,60\n",
      "dri,61\n",
      "eight,62\n",
      "eleven,63\n",
      "everi,64\n",
      "everyth,65\n",
      "extra,66\n",
      "fanta,67\n",
      "fat,68\n",
      "feta,69\n",
      "fifteen,70\n",
      "five,71\n",
      "fl,72\n",
      "flake,73\n",
      "fluid,74\n",
      "four,75\n",
      "fourteen,76\n",
      "free,77\n",
      "fri,78\n",
      "garlic,79\n",
      "ginger,80\n",
      "glaze,81\n",
      "gluten,82\n",
      "glutenfre,83\n",
      "green,84\n",
      "grill,85\n",
      "ground,86\n",
      "ham,87\n",
      "hate,88\n",
      "have,89\n",
      "hawaiian,90\n",
      "high,91\n",
      "hold,92\n",
      "hot,93\n",
      "ice,94\n",
      "italian,95\n",
      "jalapeno,96\n",
      "just,97\n",
      "kalamata,98\n",
      "keto,99\n",
      "larg,100\n",
      "leav,101\n",
      "lemon,102\n",
      "lettuc,103\n",
      "liter,104\n",
      "littl,105\n",
      "lot,106\n",
      "lover,107\n",
      "low,108\n",
      "lunch,109\n",
      "mani,110\n",
      "margarita,111\n",
      "margherita,112\n",
      "meat,113\n",
      "meatbal,114\n",
      "meatlov,115\n",
      "med,116\n",
      "mediterranean,117\n",
      "medium,118\n",
      "mexican,119\n",
      "millilit,120\n",
      "ml,121\n",
      "mountain,122\n",
      "mozarella,123\n",
      "mozzarella,124\n",
      "much,125\n",
      "mushroom,126\n",
      "napolitan,127\n",
      "napolitana,128\n",
      "neapolitan,129\n",
      "need,130\n",
      "new,131\n",
      "nine,132\n",
      "no,133\n",
      "not,134\n",
      "of,135\n",
      "oil,136\n",
      "oliv,137\n",
      "one,138\n",
      "onion,139\n",
      "onli,140\n",
      "oregano,141\n",
      "ounc,142\n",
      "oz,143\n",
      "pan,144\n",
      "parmesan,145\n",
      "parsley,146\n",
      "parti,147\n",
      "pea,148\n",
      "pecorino,149\n",
      "pellegrino,150\n",
      "peper,151\n",
      "peperoni,152\n",
      "peperonni,153\n",
      "peperroni,154\n",
      "peperronni,155\n",
      "pepper,156\n",
      "pepperoni,157\n",
      "peppperoni,158\n",
      "pepsi,159\n",
      "perrier,160\n",
      "person,161\n",
      "pesto,162\n",
      "pickl,163\n",
      "pie,164\n",
      "pineapl,165\n",
      "pineappl,166\n",
      "pizza,167\n",
      "pork,168\n",
      "powder,169\n",
      "pull,170\n",
      "ranch,171\n",
      "red,172\n",
      "regular,173\n",
      "ricotta,174\n",
      "rise,175\n",
      "roast,176\n",
      "rosemari,177\n",
      "salami,178\n",
      "san,179\n",
      "sauc,180\n",
      "sausag,181\n",
      "seven,182\n",
      "shrimp,183\n",
      "six,184\n",
      "sixteen,185\n",
      "size,186\n",
      "small,187\n",
      "soda,188\n",
      "sourdough,189\n",
      "spice,190\n",
      "spici,191\n",
      "spinach,192\n",
      "sprite,193\n",
      "stuf,194\n",
      "style,195\n",
      "suprem,196\n",
      "tea,197\n",
      "ten,198\n",
      "the,199\n",
      "thick,200\n",
      "thin,201\n",
      "thirteen,202\n",
      "three,203\n",
      "threelit,204\n",
      "tini,205\n",
      "tomato,206\n",
      "top,207\n",
      "tuna,208\n",
      "twelv,209\n",
      "two,210\n",
      "twolit,211\n",
      "up,212\n",
      "vegan,213\n",
      "veget,214\n",
      "vegetarian,215\n",
      "veggi,216\n",
      "want,217\n",
      "water,218\n",
      "white,219\n",
      "with,220\n",
      "without,221\n",
      "wood,222\n",
      "work,223\n",
      "yellow,224\n",
      "york,225\n",
      "yorker,226\n",
      "zero,227\n",
      "<PAD>,0\n",
      "<UNK>,1\n"
     ]
    }
   ],
   "source": [
    "for word, idx in word2idx.items():\n",
    "    print(f\"{word},{idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33bc4276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CONTAINERTYPE': 0, 'DRINKTYPE': 1, 'NONE': 2, 'NOT_STYLE': 3, 'NOT_TOPPING': 4, 'NUMBER': 5, 'PIZZA': 6, 'QUANTITY': 7, 'SIZE': 8, 'STYLE': 9, 'TOPPING': 10, 'VOLUME': 11}\n"
     ]
    }
   ],
   "source": [
    "print(label2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a0f1217",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T18:05:58.763027Z",
     "iopub.status.busy": "2024-12-04T18:05:58.762806Z",
     "iopub.status.idle": "2024-12-04T18:06:14.963363Z",
     "shell.execute_reply": "2024-12-04T18:06:14.962439Z"
    },
    "papermill": {
     "duration": 16.206447,
     "end_time": "2024-12-04T18:06:14.965189",
     "exception": false,
     "start_time": "2024-12-04T18:05:58.758742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Dataset Started\n",
      "Preparing Dataset Done\n"
     ]
    }
   ],
   "source": [
    "# Prepare Dataset\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, sentences, labels, word2idx, label2idx, max_len=50):\n",
    "        self.sentences = [[word2idx.get(word, word2idx['<UNK>']) for word in sentence] for sentence in sentences]\n",
    "        self.labels = [[label2idx.get(label, label2idx[\"QUANTITY\"]) for label in label_list] for label_list in labels]\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.sentences[idx]\n",
    "        label = self.labels[idx]\n",
    "        sentence = sentence[:self.max_len] + [0] * (self.max_len - len(sentence))\n",
    "        label = label[:self.max_len] + [label2idx['NONE']] * (self.max_len - len(label))\n",
    "        return torch.tensor(sentence), torch.tensor(label)\n",
    "\n",
    "print(\"Preparing Dataset Started\")\n",
    "train_dataset = SequenceDataset(train_sentences, train_labels, word2idx, label2idx)\n",
    "test_dataset = SequenceDataset(test_sentences, test_labels, word2idx, label2idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "print(\"Preparing Dataset Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c357693",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T18:06:14.973769Z",
     "iopub.status.busy": "2024-12-04T18:06:14.973469Z",
     "iopub.status.idle": "2024-12-04T18:06:14.978717Z",
     "shell.execute_reply": "2024-12-04T18:06:14.977946Z"
    },
    "papermill": {
     "duration": 0.011421,
     "end_time": "2024-12-04T18:06:14.980368",
     "exception": false,
     "start_time": "2024-12-04T18:06:14.968947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Model\n",
    "class RNNSequenceLabeling(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(RNNSequenceLabeling, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=word2idx['<PAD>'])\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, \n",
    "                            num_layers=2, \n",
    "                            bidirectional=True, \n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        predicted = self.fc(lstm_out)\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca8eb6dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T18:06:14.988169Z",
     "iopub.status.busy": "2024-12-04T18:06:14.987934Z",
     "iopub.status.idle": "2024-12-04T18:06:15.049551Z",
     "shell.execute_reply": "2024-12-04T18:06:15.048700Z"
    },
    "papermill": {
     "duration": 0.0674,
     "end_time": "2024-12-04T18:06:15.051214",
     "exception": false,
     "start_time": "2024-12-04T18:06:14.983814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7592\\2581168607.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('models/active/Entity.pth', map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RNNSequenceLabeling(\n",
       "  (embedding): Embedding(228, 100, padding_idx=0)\n",
       "  (lstm): LSTM(100, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "vocab_size = len(word2idx)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 128\n",
    "output_dim = len(label2idx)\n",
    "\n",
    "model = RNNSequenceLabeling(vocab_size, embedding_dim, hidden_dim, output_dim).to(device)\n",
    "model.load_state_dict(torch.load('models/active/Entity.pth', map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87767f22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T18:06:15.059371Z",
     "iopub.status.busy": "2024-12-04T18:06:15.059143Z",
     "iopub.status.idle": "2024-12-04T20:30:14.193019Z",
     "shell.execute_reply": "2024-12-04T20:30:14.192019Z"
    },
    "papermill": {
     "duration": 8639.14414,
     "end_time": "2024-12-04T20:30:14.198914",
     "exception": false,
     "start_time": "2024-12-04T18:06:15.054774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Started\n",
      "Epoch 1/20, Loss: 0.0008272594174388413082802\n",
      "Epoch 2/20, Loss: 0.0000000000492898536707681\n",
      "Epoch 3/20, Loss: 0.0000000000082441232608919\n",
      "Epoch 4/20, Loss: 0.0000000000049044159261700\n",
      "Epoch 5/20, Loss: 0.0000000000036028010328189\n",
      "Epoch 6/20, Loss: 0.0000000000028777762404607\n",
      "Epoch 7/20, Loss: 0.0000000000024361614213390\n",
      "Epoch 8/20, Loss: 0.0000000000021498397217536\n",
      "Epoch 9/20, Loss: 0.0000000000020081347981390\n",
      "Epoch 10/20, Loss: 0.0000000000018848709002082\n",
      "Epoch 11/20, Loss: 0.0000000000048567948986891\n",
      "Epoch 12/20, Loss: 0.0000000000308412314694920\n",
      "Epoch 13/20, Loss: 0.0000005678250542069031777\n",
      "Epoch 14/20, Loss: 0.0000000191948637415595313\n",
      "Epoch 15/20, Loss: 0.0000008389367586936262401\n",
      "Epoch 16/20, Loss: 0.0000006606241880591917679\n",
      "Epoch 17/20, Loss: 0.0000004368849924189691590\n",
      "Epoch 18/20, Loss: 0.0000009468243555622430261\n",
      "Epoch 19/20, Loss: 0.0000003498500169720110484\n",
      "Epoch 20/20, Loss: 0.0000018562301402992116068\n",
      "Training Done\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "print(\"Training Started\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "vocab_size = len(word2idx)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 128\n",
    "output_dim = len(label2idx)\n",
    "\n",
    "model = RNNSequenceLabeling(vocab_size, embedding_dim, hidden_dim, output_dim).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for sentences, labels in train_loader:\n",
    "        sentences, labels = sentences.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(sentences)\n",
    "\n",
    "        loss = criterion(predictions.view(-1, output_dim), labels.view(-1)) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    torch.save(model.state_dict(), f\"BLSTM_IT_{epoch + 1}.pth\")\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader):.25f}\")\n",
    "print(\"Training Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "862fc5b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T20:30:14.209252Z",
     "iopub.status.busy": "2024-12-04T20:30:14.208439Z",
     "iopub.status.idle": "2024-12-04T20:30:14.275533Z",
     "shell.execute_reply": "2024-12-04T20:30:14.274746Z"
    },
    "papermill": {
     "duration": 0.074,
     "end_time": "2024-12-04T20:30:14.277249",
     "exception": false,
     "start_time": "2024-12-04T20:30:14.203249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Started\n",
      "Test Accuracy: 95.22%\n",
      "Testing Done\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "def evaluate(model, loader):\n",
    "    global label2idx, idx2word\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for sentences, labels in loader:\n",
    "            sentences, labels = sentences.to(device), labels.to(device)\n",
    "            predictions = model(sentences).argmax(dim=-1)\n",
    "            total += labels.numel()\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            # for sentence, predict, label in zip(sentences, predictions, labels):\n",
    "            #     if (predict != label).sum().item() > 0:\n",
    "            #         for word in sentence:\n",
    "            #             print(idx2word[word.item()], end=\"\")\n",
    "            #         print()\n",
    "                    \n",
    "\n",
    "    return correct / total\n",
    "print(\"Testing Started\")\n",
    "accuracy = evaluate(model, test_loader)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Testing Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e56db8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T20:30:14.289008Z",
     "iopub.status.busy": "2024-12-04T20:30:14.288768Z",
     "iopub.status.idle": "2024-12-04T20:30:14.296735Z",
     "shell.execute_reply": "2024-12-04T20:30:14.296016Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.014978,
     "end_time": "2024-12-04T20:30:14.298277",
     "exception": false,
     "start_time": "2024-12-04T20:30:14.283299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "PUNCTUATIONS=[\n",
    "    \".\",  # Period\n",
    "    \",\",  # Comma\n",
    "    \";\",  # Semicolon\n",
    "    \":\",  # Colon\n",
    "    \"!\",  # Exclamation Mark\n",
    "    \"?\",  # Question Mark\n",
    "    \"'\",  # Apostrophe\n",
    "    '\"',  # Quotation Marks\n",
    "    \"_\",  # Em Dash\n",
    "    \"-\",  # Hyphen\n",
    "    \"[\",  # Left Bracket\n",
    "    \"]\",  # Right Bracket\n",
    "    \"{\",  # Left Brace\n",
    "    \"}\",  # Right Brace\n",
    "    \"/\",  # Slash\n",
    "    \"\\\\\", # Backslash\n",
    "    \"|\",  # Vertical Bar\n",
    "    \"@\",  # At Symbol\n",
    "    \"#\",  # Hash\n",
    "    \"$\",  # Dollar Sign\n",
    "    \"%\",  # Percent\n",
    "    \"^\",  # Caret\n",
    "    \"&\",  # Ampersand\n",
    "    \"*\",  # Asterisk\n",
    "    \"_\",  # Underscore\n",
    "    \"+\",  # Plus\n",
    "    \"=\",  # Equals\n",
    "    \"<\",  # Less Than\n",
    "    \">\",  # Greater Than\n",
    "    \"~\",  # Tilde\n",
    "    \"`\"   # Grave Accent\n",
    "]\n",
    "\n",
    "BLACKLIST = [\n",
    "    # human references\n",
    "    'i', 'me', 'my', 'mine', 'myself',\n",
    "    'you', 'your', 'yourself',\n",
    "    'he', 'him', 'hi', 'himself',\n",
    "    'she', 'her', 'herself',\n",
    "    'it', 'itself',\n",
    "    'we', 'us', 'our', 'ourselv',\n",
    "    'they', 'them', 'their', 'themselv',\n",
    "    'person', 'peopl', 'human',\n",
    "    'individu', 'man', 'men',\n",
    "    'woman', 'women', 'child', 'children',\n",
    "    'adult', 'someon', 'somebodi',\n",
    "    'anyon', 'anybodi', 'everyon', 'everybodi',\n",
    "    'no on', 'nobodi'\n",
    "\n",
    "    # admiring something (who cares cry about it)\n",
    "    \"love\", \"like\", \"admire\", \"adore\", \"cherish\", \n",
    "    \"appreciate\", \"respect\", \"idolize\", \"enjoy\", \n",
    "    \"value\", \"revere\", \"treasure\", \"favor\", \n",
    "    \"prefer\", \"esteem\", \"venerate\", \"worship\", \n",
    "    \"fancy\", \"savor\", \"delight\", \"care\"\n",
    "\n",
    "    # extra\n",
    "    'the', 'and', 'or', 'but', 'within', 'to', 'by', \n",
    "\n",
    "    'id', 'ive', 'iam', 'along', 'on', 'in', 'over'\n",
    "]\n",
    "\n",
    "PIZZA_WORDS = [\"pizza\", \"pie\", \"slice\"]\n",
    "\n",
    "\n",
    "\n",
    "BLACKLIST    = list(set([ stemmer.stem(x) for x in BLACKLIST ]))\n",
    "PIZZA_WORDS  = list(set([ stemmer.stem(x) for x in PIZZA_WORDS]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43e7c951",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T20:30:14.308427Z",
     "iopub.status.busy": "2024-12-04T20:30:14.307867Z",
     "iopub.status.idle": "2024-12-04T20:30:14.315632Z",
     "shell.execute_reply": "2024-12-04T20:30:14.314934Z"
    },
    "papermill": {
     "duration": 0.014436,
     "end_time": "2024-12-04T20:30:14.317144",
     "exception": false,
     "start_time": "2024-12-04T20:30:14.302708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "class Normalizer:\n",
    "    ''' \n",
    "        Removes All Punctuation From The Given String \n",
    "        Punctuation will is defined in var.py\n",
    "    '''\n",
    "    def remove_punctuations(self, TOP):\n",
    "        regex = \"\".join([ fr\"\\{punc}\" for punc in PUNCTUATIONS ])\n",
    "        TOP = re.sub(fr\"[{regex}]\", '', TOP)\n",
    "        return TOP\n",
    "    \n",
    "    '''\n",
    "        Removes Words From The Given String Which Are Defined In var.py\n",
    "        Note: This Words Is Assumed To Be Stemmed Already\n",
    "    '''\n",
    "    def remove_words(self, TOP):\n",
    "        regex = fr\"(?<=(?:\\b|^))(?:{'|'.join(BLACKLIST)})(?=(?:\\b|&))\"\n",
    "        return re.sub(fr\"({regex})\", '', TOP)\n",
    "\n",
    "    def replace_numbers(self, TOP):\n",
    "        regex = r'\\b(?:\\d+|a)\\b' # TODO: revise this\n",
    "        TOP = re.sub(regex, 'DIGIT', TOP)\n",
    "        return TOP\n",
    "\n",
    "    '''\n",
    "        Follow Rules Of Replacing Some Words With Other In Case Of Needing\n",
    "    '''\n",
    "    def reconstruct_words(self, TOP):\n",
    "        return TOP\n",
    "    \n",
    "    '''\n",
    "        - Replace Multiple Spaces With Only One Space\n",
    "        - Removes Spaces At The Beginning And End Of The Given String\n",
    "    '''\n",
    "    def reorganize_spaces(self, TOP):\n",
    "        TOP = re.sub(r'\\s+', ' ', TOP)\n",
    "        return re.sub(r'(?:\\s+$)|(?:^\\s+)', '', TOP)\n",
    "    \n",
    "    '''\n",
    "        Stems the given word and convert it to lowercase\n",
    "    '''\n",
    "    def stem_word(self, token):\n",
    "        return stemmer.stem(token)\n",
    "\n",
    "    '''\n",
    "        Stems the given sentence and convert all words to lowercase\n",
    "    '''\n",
    "    def stem_sentence(self, sentence):\n",
    "        return \" \".join([ self.stem_word(word) for word in sentence.split(' ') ])\n",
    "\n",
    "    '''\n",
    "        Normalizes the given sentence by performing the following steps:\n",
    "        1. Reconstructs the words using the rules defined in var\n",
    "        2. Removes punctuation defined in var\n",
    "        3. Reorganizes spaces\n",
    "        4. Stems the sentence\n",
    "        5. Returns the normalized sentence\n",
    "    '''\n",
    "    def normalize(self, sentence):\n",
    "        NEXT = self.remove_punctuations(sentence) \n",
    "        NEXT = self.remove_words(NEXT)\n",
    "        NEXT = self.replace_numbers(NEXT)\n",
    "        NEXT = self.reconstruct_words(NEXT)\n",
    "        NEXT = self.reorganize_spaces(NEXT)\n",
    "        NEXT = self.stem_sentence(NEXT)\n",
    "        return NEXT\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23abc6ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T20:30:14.326584Z",
     "iopub.status.busy": "2024-12-04T20:30:14.326369Z",
     "iopub.status.idle": "2024-12-04T20:30:14.331136Z",
     "shell.execute_reply": "2024-12-04T20:30:14.330384Z"
    },
    "papermill": {
     "duration": 0.011249,
     "end_time": "2024-12-04T20:30:14.332678",
     "exception": false,
     "start_time": "2024-12-04T20:30:14.321429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict labels for a single query\n",
    "def preprocess_sentence(sentence, word2idx, max_len=50):\n",
    "    normalizer = Normalizer()\n",
    "    preprocessed = normalizer.normalize(sentence)\n",
    "    preprocessed = normalizer.reorganize_spaces(preprocessed)\n",
    "    preprocessed = preprocessed.replace(\"digit\", \"DIGIT\")\n",
    "    \n",
    "    print (f\"After Preprocessing: {preprocessed}\")\n",
    "    words = preprocessed.split()  # Tokenize the sentence\n",
    "    indices = [word2idx.get(word, word2idx['<UNK>']) for word in words]  # Map words to indices\n",
    "    indices = indices[:max_len] + [0] * (max_len - len(indices))  # Pad or truncate\n",
    "    return torch.tensor([indices])  # Add batch dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e22cb33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T20:30:14.342165Z",
     "iopub.status.busy": "2024-12-04T20:30:14.341929Z",
     "iopub.status.idle": "2024-12-04T20:30:14.346635Z",
     "shell.execute_reply": "2024-12-04T20:30:14.345863Z"
    },
    "papermill": {
     "duration": 0.011183,
     "end_time": "2024-12-04T20:30:14.348134",
     "exception": false,
     "start_time": "2024-12-04T20:30:14.336951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict labels for a single query\n",
    "def predict_labels(model, sentence, word2idx, idx2label, device, max_len=50):\n",
    "    input_tensor = preprocess_sentence(sentence, word2idx, max_len).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)  # Get logits\n",
    "        predictions = output.argmax(dim=-1).squeeze(0)  # Get label indices\n",
    "    return [idx2label[idx.item()] for idx in predictions if idx.item() in idx2label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b943ae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T20:30:14.357888Z",
     "iopub.status.busy": "2024-12-04T20:30:14.357402Z",
     "iopub.status.idle": "2024-12-04T20:30:14.366335Z",
     "shell.execute_reply": "2024-12-04T20:30:14.365458Z"
    },
    "papermill": {
     "duration": 0.015454,
     "end_time": "2024-12-04T20:30:14.367940",
     "exception": false,
     "start_time": "2024-12-04T20:30:14.352486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: i'd like a medium pizza with marinara sauce, extra cheese and pepperoni\n",
      "After Preprocessing: DIGIT medium pizza with marinara sauc extra chees pepperoni\n",
      "Predicted Labels: ['NUMBER', 'SIZE', 'PIZZA', 'NONE', 'VOLUME', 'TOPPING', 'QUANTITY', 'TOPPING', 'TOPPING', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE']\n"
     ]
    }
   ],
   "source": [
    "# Example testing\n",
    "new_sentence = \"i'd like a medium pizza with marinara sauce, extra cheese and pepperoni\"\n",
    "\n",
    "print(f\"Sentence: {new_sentence}\")\n",
    "predicted_labels = predict_labels(model, new_sentence, word2idx, idx2label, device)\n",
    "print(f\"Predicted Labels: {predicted_labels}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6223286,
     "sourceId": 10100829,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8702.377174,
   "end_time": "2024-12-04T20:30:17.491954",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-04T18:05:15.114780",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
