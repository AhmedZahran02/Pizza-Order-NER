{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10090626,"sourceType":"datasetVersion","datasetId":6222132}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:09:10.740413Z","iopub.execute_input":"2024-12-03T18:09:10.740797Z","iopub.status.idle":"2024-12-03T18:09:10.745678Z","shell.execute_reply.started":"2024-12-03T18:09:10.740764Z","shell.execute_reply":"2024-12-03T18:09:10.744713Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Load Data\ndef load_data(file_x, file_y):\n    with open(file_x, 'r') as fx, open(file_y, 'r') as fy:\n        sentences = fx.read().strip().split('\\n')\n        labels = fy.read().strip().split('\\n')\n    return [sentence.split() for sentence in sentences], [label.split(',') for label in labels]\n\nprint(\"Loading Data Started\")\ntrain_sentences, train_labels = load_data('../input/pizza-dataset/train_x.txt', '../input/pizza-dataset/train_y.txt')\ntest_sentences, test_labels = load_data('../input/pizza-dataset/test_x.txt', '../input/pizza-dataset/test_y.txt')\nprint(\"Loading Data Done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:09:16.770424Z","iopub.execute_input":"2024-12-03T18:09:16.771262Z","iopub.status.idle":"2024-12-03T18:09:43.004725Z","shell.execute_reply.started":"2024-12-03T18:09:16.771224Z","shell.execute_reply":"2024-12-03T18:09:43.003717Z"}},"outputs":[{"name":"stdout","text":"Loading Data Started\nLoading Data Done\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Build Vocabulary\ndef build_vocab(sentences):\n    vocab = {word for sentence in sentences for word in sentence}\n    word2idx = {word: idx + 1 for idx, word in enumerate(sorted(vocab))}  # Reserve 0 for padding\n    word2idx['<PAD>'] = 0\n    return word2idx\n\ndef build_label_vocab(labels):\n    vocab = {label for label_list in labels for label in label_list}\n    label2idx = {label: idx for idx, label in enumerate(sorted(vocab))}\n    return label2idx\n\nprint(\"Building Vocab Started\")\nword2idx = build_vocab(train_sentences + test_sentences)\nlabel2idx = build_label_vocab(train_labels + test_labels)\nidx2label = {idx: label for label, idx in label2idx.items()}\nprint(\"Building Vocab Done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:09:57.010278Z","iopub.execute_input":"2024-12-03T18:09:57.011164Z","iopub.status.idle":"2024-12-03T18:10:00.887367Z","shell.execute_reply.started":"2024-12-03T18:09:57.011127Z","shell.execute_reply":"2024-12-03T18:10:00.886266Z"}},"outputs":[{"name":"stdout","text":"Building Vocab Started\nBuilding Vocab Done\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# Prepare Dataset\nclass SequenceDataset(Dataset):\n    def __init__(self, sentences, labels, word2idx, label2idx, max_len=50):\n        self.sentences = [[word2idx[word] for word in sentence] for sentence in sentences]\n        self.labels = [[label2idx[label] for label in label_list] for label_list in labels]\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.sentences)\n\n    def __getitem__(self, idx):\n        sentence = self.sentences[idx]\n        label = self.labels[idx]\n        sentence = sentence[:self.max_len] + [0] * (self.max_len - len(sentence))\n        label = label[:self.max_len] + [label2idx['NONE']] * (self.max_len - len(label))\n        return torch.tensor(sentence), torch.tensor(label)\n\nprint(\"Preparing Dataset Started\")\ntrain_dataset = SequenceDataset(train_sentences, train_labels, word2idx, label2idx)\ntest_dataset = SequenceDataset(test_sentences, test_labels, word2idx, label2idx)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32)\nprint(\"Preparing Dataset Done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:10:05.709392Z","iopub.execute_input":"2024-12-03T18:10:05.710431Z","iopub.status.idle":"2024-12-03T18:10:23.510038Z","shell.execute_reply.started":"2024-12-03T18:10:05.710377Z","shell.execute_reply":"2024-12-03T18:10:23.509019Z"}},"outputs":[{"name":"stdout","text":"Preparing Dataset Started\nPreparing Dataset Done\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# Define Model\nclass RNNSequenceLabeling(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n        super(RNNSequenceLabeling, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, \n                            num_layers=2, \n                            bidirectional=True, \n                            batch_first=True)\n        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n\n    def forward(self, x):\n        embedded = self.embedding(x)\n        lstm_out, _ = self.lstm(embedded)\n        logits = self.fc(lstm_out)\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:10:31.673832Z","iopub.execute_input":"2024-12-03T18:10:31.674209Z","iopub.status.idle":"2024-12-03T18:10:31.680548Z","shell.execute_reply.started":"2024-12-03T18:10:31.674161Z","shell.execute_reply":"2024-12-03T18:10:31.679585Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# Training\nprint(\"Training Started\")\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nvocab_size = len(word2idx)\nembedding_dim = 100\nhidden_dim = 128\noutput_dim = len(label2idx)\n\nmodel = RNNSequenceLabeling(vocab_size, embedding_dim, hidden_dim, output_dim).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0\n    for sentences, labels in train_loader:\n        sentences, labels = sentences.to(device), labels.to(device)\n        optimizer.zero_grad()\n        predictions = model(sentences)\n        loss = criterion(predictions.view(-1, output_dim), labels.view(-1))\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}\")\nprint(\"Training Done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T18:10:35.713948Z","iopub.execute_input":"2024-12-03T18:10:35.714799Z"}},"outputs":[{"name":"stdout","text":"Training Started\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Evaluation\ndef evaluate(model, loader):\n    model.eval()\n    total, correct = 0, 0\n    with torch.no_grad():\n        for sentences, labels in loader:\n            sentences, labels = sentences.to(device), labels.to(device)\n            predictions = model(sentences).argmax(dim=-1)\n            total += labels.numel()\n            correct += (predictions == labels).sum().item()\n    return correct / total\nprint(\"Testing Started\")\naccuracy = evaluate(model, test_loader)\nprint(f\"Test Accuracy: {accuracy * 100:.2f}%\")\nprint(\"Testing Done\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}